# Kaggles
Kaggle code

# 1. Titanic

The Titanic dataset and example is super old. It is a great example of how a Random Forest can be applied well. Here, we essentially use multiple decision trees with default/sensible assumptions to generate Kaggle predictions. The score is c.75%, where the best submissions are around 80-83%. Leaderboard position is not relevant, since there are multiple entries that have "cheated" by utilising the list of survivors/deceased which is publicly available online
